CONTAINER ID   IMAGE                         COMMAND                  CREATED          STATUS                      PORTS                                                                                                                                                           NAMES
215251f21cf5   tabulario/spark-iceberg       "/bin/sh -c ' sleep …"   59 minutes ago   Exited (0) 58 minutes ago                                                                                                                                                                   spark-sql
6cb171848a48   tabulario/spark-iceberg       "./entrypoint.sh not…"   59 minutes ago   Up 59 minutes               0.0.0.0:8888->8888/tcp, :::8888->8888/tcp, 0.0.0.0:10000-10001->10000-10001/tcp, :::10000-10001->10000-10001/tcp, 0.0.0.0:8088->8080/tcp, [::]:8088->8080/tcp   spark-iceberg
14be4113d0bf   minio/mc:latest               "/bin/sh -c ' until …"   59 minutes ago   Up 59 minutes                                                                                                                                                                               mc
7a99504cf64b   naushadh/hive-metastore       "./run.sh"               59 minutes ago   Up 59 minutes (healthy)     0.0.0.0:9083->9083/tcp, :::9083->9083/tcp                                                                                                                       hive-metastore
b3781c0c68ac   tabulario/iceberg-rest        "java -jar iceberg-r…"   59 minutes ago   Up 59 minutes               0.0.0.0:8181->8181/tcp, :::8181->8181/tcp                                                                                                                       iceberg-rest
983784b02919   projectnessie/nessie:latest   "/usr/local/s2i/run"     59 minutes ago   Up 59 minutes               8080/tcp, 8443/tcp, 0.0.0.0:19120->19120/tcp, :::19120->19120/tcp                                                                                               nessie
f1d15121b2ec   minio/minio                   "/usr/bin/docker-ent…"   59 minutes ago   Up 59 minutes               0.0.0.0:9000-9001->9000-9001/tcp, :::9000-9001->9000-9001/tcp                                                                                                   minio
22b69749d178   postgres:14                   "docker-entrypoint.s…"   59 minutes ago   Up 59 minutes               0.0.0.0:5433->5432/tcp, [::]:5433->5432/tcp    



https://repo1.maven.org/maven2/org/apache/hive/hive-jdbc/2.3.9/hive-jdbc-2.3.9-standalone.jar



ubuntu@ip-172-31-10-68:~/spark-3.5.6-bin-hadoop3$ ~/spark-3.5.6-bin-hadoop3/bin/pyspark   --jars ~/.ivy2/jars/org.apache.iceberg_iceberg-spark-runtime-3.5_2.12-1.5.2.jar   --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions   --conf spark.sql.catalog.vendor_catalog=org.apache.iceberg.spark.SparkCatalog   --conf spark.sql.catalog.vendor_catalog.type=hadoop   --conf spark.sql.catalog.vendor_catalog.warehouse=/tmp/warehouse
Python 3.10.12 (main, Aug 15 2025, 14:32:43) [GCC 11.4.0] on linux
Type "help", "copyright", "credits" or "license" for more information.
25/09/16 09:23:22 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
Setting default log level to "WARN".
To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).
Welcome to
      ____              __
     / __/__  ___ _____/ /__
    _\ \/ _ \/ _ `/ __/  '_/
   /__ / .__/\_,_/_/ /_/\_\   version 3.5.6
      /_/

Using Python version 3.10.12 (main, Aug 15 2025 14:32:43)
Spark context Web UI available at http://ip-172-31-10-68.ap-south-1.compute.internal:4040
Spark context available as 'sc' (master = local[*], app id = local-1758014604345).
SparkSession available as 'spark'.
>>> spark.sql("select * from vendor_catalog.vendor_db.demo").show()
+---+----+                                                                      
| id|name|
+---+----+
|  1|John|
|  2|Alka|
+---+----+

$SPARK_HOME/sbin/start-thriftserver.sh \
  --master local[*] \
  --conf spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions \
  --conf spark.sql.catalog.vendor_catalog=org.apache.iceberg.spark.SparkCatalog \
  --conf spark.sql.catalog.vendor_catalog.type=hadoop \
  --conf spark.sql.catalog.vendor_catalog.warehouse=/tmp/warehouse
beeline -u "jdbc:hive2://localhost:10000" -e "SELECT * FROM vendor_catalog.vendor_db.demo"

beeline -u "jdbc:hive2://localhost:10000/default;catalog=vendor_catalog" -e "SHOW TABLES IN vendor_db"
